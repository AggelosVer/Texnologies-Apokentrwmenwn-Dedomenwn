{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Dataset - Exploratory Data Analysis (EDA)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "# Load only first 10,000 rows for analysis (full dataset is 946K rows)\n",
    "# Using latin-1 encoding to handle special characters\n",
    "df = pd.read_csv('data_movies_clean.csv', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "\n",
    "# CLEANING STEP: Remove rows where the title is missing\n",
    "# This removes the \"nan\" spike and ensures a uniform distribution\n",
    "df = df.dropna(subset=['title'])\n",
    "df.columns = [col.split(';')[0] if isinstance(col, str) else col for col in df.columns]\n",
    "\n",
    "# Coerce numeric columns to fix mixed types\n",
    "numeric_cols = ['budget', 'revenue', 'runtime', 'vote_average']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "print(f\"Loaded {len(df)} movies (after cleaning missing titles)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Key Columns for DHT Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns used in DHT\n",
    "print(\"Key Columns for DHT:\")\n",
    "print(\"\\n1. PRIMARY KEY: 'title' - Used as DHT key for hashing\")\n",
    "print(\"\\n2. SEARCHABLE ATTRIBUTES (B+ tree indexed):\")\n",
    "print(\"   - popularity (numeric)\")\n",
    "print(\"   - vote_average (numeric)\")\n",
    "print(\"   - release_date (temporal)\")\n",
    "print(\"\\n3. METADATA ATTRIBUTES:\")\n",
    "print(\"   - budget, revenue, runtime\")\n",
    "print(\"   - genre_names, production_company_names\")\n",
    "print(\"   - original_language, origin_country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Distribution Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Popularity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popularity distribution\n",
    "if 'popularity' in df.columns:\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df['popularity'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Popularity Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Popularity Distribution (Full Range)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Log scale for better visualization\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(df['popularity'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Popularity Score')\n",
    "    plt.ylabel('Frequency (log scale)')\n",
    "    plt.title('Popularity Distribution (Log Scale)')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Popularity Statistics:\")\n",
    "    print(f\"  Mean: {df['popularity'].mean():.2f}\")\n",
    "    print(f\"  Median: {df['popularity'].median():.2f}\")\n",
    "    print(f\"  Min: {df['popularity'].min():.2f}\")\n",
    "    print(f\"  Max: {df['popularity'].max():.2f}\")\n",
    "else:\n",
    "    print(\"'popularity' column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Rating Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating distribution\n",
    "if 'vote_average' in df.columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.hist(df['vote_average'].dropna(), bins=30, edgecolor='black', alpha=0.7, color='coral')\n",
    "    plt.xlabel('Average Rating')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Movie Rating Distribution')\n",
    "    plt.axvline(df['vote_average'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"vote_average\"].mean():.2f}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Rating Statistics:\")\n",
    "    print(f\"  Mean: {df['vote_average'].mean():.2f}\")\n",
    "    print(f\"  Median: {df['vote_average'].median():.2f}\")\n",
    "    print(f\"  Std Dev: {df['vote_average'].std():.2f}\")\n",
    "else:\n",
    "    print(\"'vote_average' column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Release Year Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from release_date\n",
    "if 'release_date' in df.columns:\n",
    "    df['year'] = pd.to_datetime(df['release_date'], errors='coerce').dt.year\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Movies per year\n",
    "    year_counts = df['year'].value_counts().sort_index()\n",
    "    plt.plot(year_counts.index, year_counts.values, linewidth=2, color='steelblue')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number of Movies')\n",
    "    plt.title('Movie Production Over Time')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Year Range: {df['year'].min():.0f} - {df['year'].max():.0f}\")\n",
    "    print(f\"Most productive year: {year_counts.idxmax():.0f} ({year_counts.max()} movies)\")\n",
    "else:\n",
    "    print(\"'release_date' column not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Budget and Revenue Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget vs Revenue\n",
    "if 'budget' in df.columns and 'revenue' in df.columns:\n",
    "    # Filter out zero values\n",
    "    df_filtered = df[(df['budget'] > 0) & (df['revenue'] > 0)].copy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df_filtered['budget'], df_filtered['revenue'], alpha=0.5, s=30)\n",
    "    plt.xlabel('Budget ($)')\n",
    "    plt.ylabel('Revenue ($)')\n",
    "    plt.title('Budget vs Revenue')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    # Add diagonal line (break-even)\n",
    "    max_val = max(df_filtered['budget'].max(), df_filtered['revenue'].max())\n",
    "    plt.plot([1, max_val], [1, max_val], 'r--', linewidth=2, label='Break-even')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # ROI calculation\n",
    "    df_filtered.loc[:, 'roi'] = (df_filtered['revenue'] - df_filtered['budget']) / df_filtered['budget'] * 100\n",
    "    print(f\"\\nROI Statistics (non-zero budget/revenue):\")\n",
    "    print(f\"  Average ROI: {df_filtered['roi'].mean():.1f}%\")\n",
    "    print(f\"  Median ROI: {df_filtered['roi'].median():.1f}%\")\n",
    "    print(f\"  Profitable movies: {(df_filtered['roi'] > 0).sum()} / {len(df_filtered)} ({(df_filtered['roi'] > 0).sum() / len(df_filtered) * 100:.1f}%)\")\n",
    "else:\n",
    "    print(\"'budget' or 'revenue' columns not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DHT Hash Distribution Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate DHT hashing\n",
    "import hashlib\n",
    "\n",
    "def hash_title(title, m_bits=160):\n",
    "    \"\"\"Hash movie title using SHA-1\"\"\"\n",
    "    normalized = str(title).strip().lower()\n",
    "    hash_obj = hashlib.sha1(normalized.encode('utf-8'))\n",
    "    hash_int = int(hash_obj.hexdigest(), 16)\n",
    "    ring_size = 2 ** m_bits\n",
    "    return hash_int % ring_size\n",
    "\n",
    "# Hash all movie titles\n",
    "sample_df = df.copy()\n",
    "sample_df['hash_id'] = sample_df['title'].apply(lambda x: hash_title(x, m_bits=32))  # Use 32-bit for visualization\n",
    "\n",
    "print(f\"Hashed {len(sample_df)} movie titles\")\n",
    "print(f\"Hash ID range: 0 to {2**32 - 1}\")\n",
    "print(f\"\\nSample hashes:\")\n",
    "print(sample_df[['title', 'hash_id']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hash distribution\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Histogram of hash values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(sample_df['hash_id'], bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
    "plt.xlabel('Hash ID (32-bit)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Hashed Movie Titles')\n",
    "plt.annotate('Cleaning NaN titles ensures uniformity', xy=(0.5, 0.95), xycoords='axes fraction', ha='center', color='darkred')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Sorted hash IDs (shows uniform distribution)\n",
    "plt.subplot(1, 2, 2)\n",
    "sorted_hashes = sorted(sample_df['hash_id'])\n",
    "plt.plot(range(len(sorted_hashes)), sorted_hashes, linewidth=1)\n",
    "plt.xlabel('Movie Index (sorted)')\n",
    "plt.ylabel('Hash ID')\n",
    "plt.title('Sorted Hash IDs (Should be Linear for Uniform Distribution)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHash distribution is uniform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Top Movies Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top movies by popularity\n",
    "if 'popularity' in df.columns and 'title' in df.columns:\n",
    "    top_popular = df.nlargest(15, 'popularity')[['title', 'popularity']]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(range(len(top_popular)), top_popular['popularity'], color='skyblue', edgecolor='black')\n",
    "    plt.yticks(range(len(top_popular)), top_popular['title'], fontsize=10)\n",
    "    plt.xlabel('Popularity Score')\n",
    "    plt.title('Top 15 Most Popular Movies')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 15 Most Popular Movies:\")\n",
    "    print(top_popular.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Suitability for DHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DATASET SUITABILITY FOR DHT IMPLEMENTATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n PRIMARY KEY (title):\")\n",
    "print(f\"  - Total movies: {len(df):,}\")\n",
    "print(f\"  - Unique titles: {df['title'].nunique():,}\")\n",
    "print(f\"  - Uniqueness: {df['title'].nunique() / len(df) * 100:.1f}%\")\n",
    "\n",
    "if 'popularity' in df.columns:\n",
    "    print(\"\\n  SEARCHABLE ATTRIBUTE (popularity):\")\n",
    "    print(f\"  - Non-null values: {df['popularity'].notna().sum():,}\")\n",
    "    print(f\"  - Range: {df['popularity'].min():.2f} to {df['popularity'].max():.2f}\")\n",
    "    print(f\"  - Good for range queries: YES\")\n",
    "\n",
    "print(\"\\n HASH DISTRIBUTION:\")\n",
    "print(f\"  - Titles hashed: {len(sample_df):,}\")\n",
    "print(f\"  - Distribution: UNIFORM (good for load balancing)\")\n",
    "print(f\"  - Hash collisions: MINIMAL (SHA-1 160-bit)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics for Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary for experimental report\n",
    "summary = {\n",
    "    'Total Movies (sample)': len(df),\n",
    "    'Unique Titles': df['title'].nunique(),\n",
    "    'Columns': len(df.columns),\n",
    "}\n",
    "\n",
    "if 'popularity' in df.columns:\n",
    "    summary['Avg Popularity'] = f\"{df['popularity'].mean():.2f}\"\n",
    "\n",
    "if 'year' in df.columns:\n",
    "    summary['Year Range'] = f\"{df['year'].min():.0f} - {df['year'].max():.0f}\"\n",
    "\n",
    "print(\"\\nDataset Summary for Report:\")\n",
    "print(\"-\" * 50)\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key:<30}: {value}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. DHT Performance & Experimental Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Overall Latency Comparison (Chord vs Pastry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "# Display the main performance comparison\n",
    "if os.path.exists('instances/performance_comparison_bars.png'):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    img = mpimg.imread('instances/performance_comparison_bars.png')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Chord vs Pastry: Operation Latency Comparison\", fontsize=16)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Performance plot 'instances/performance_comparison_bars.png' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Scaling Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the Join and Lookup scaling\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "if os.path.exists('instances/scaling_node_join.png'):\n",
    "    ax1.imshow(mpimg.imread('instances/scaling_node_join.png'))\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(\"Node Join Scaling\")\n",
    "\n",
    "if os.path.exists('instances/scaling_lookup.png'):\n",
    "    ax2.imshow(mpimg.imread('instances/scaling_lookup.png'))\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title(\"Lookup Latency Scaling\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Concurrency & K-Parameter Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display concurrency scaling\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "if os.path.exists('instances/concurrency_scaling.png'):\n",
    "    ax1.imshow(mpimg.imread('instances/concurrency_scaling.png'))\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(\"Total Time vs K (Concurrent Lookups)\")\n",
    "\n",
    "if os.path.exists('instances/concurrency_avg_latency.png'):\n",
    "    ax2.imshow(mpimg.imread('instances/concurrency_avg_latency.png'))\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title(\"Average Latency per Movie vs K\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
